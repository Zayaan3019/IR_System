{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing the essential libraries"
      ],
      "metadata": {
        "id": "UiB5Cqx6kOo-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXPpSh2VnyDL",
        "outputId": "cd046d93-85cc-451d-cdcd-2a829f51d2c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the documents"
      ],
      "metadata": {
        "id": "Sl3UbSa9kUSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = {\n",
        "    \"d1\": \"Herbivores are typically plant eaters and not meat eaters\",\n",
        "    \"d2\": \"Carnivores are typically meat eaters and not plant eaters\",\n",
        "    \"d3\": \"Deers eat grass and leaves\"\n",
        "}\n",
        "\n",
        "custom_stopwords = {\"are\", \"and\", \"not\"}"
      ],
      "metadata": {
        "id": "DlJU_A3RrEzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing the documents"
      ],
      "metadata": {
        "id": "MvTbrD7ykbGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    filtered_tokens = [t for t in tokens if t.isalpha() and t not in custom_stopwords]\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(t) for t in filtered_tokens]\n",
        "    return lemmatized_tokens"
      ],
      "metadata": {
        "id": "fv7qNnTeDPoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing the preprocessed documents"
      ],
      "metadata": {
        "id": "9iL_pzJNktAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_docs = {}\n",
        "print(\"Preprocessed Documents:\")\n",
        "for doc_id, text in documents.items():\n",
        "    preprocessed = preprocess(text)\n",
        "    preprocessed_docs[doc_id] = preprocessed\n",
        "    print(f\"{doc_id}: {preprocessed}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmcFYHhADoua",
        "outputId": "3a66ece5-e9ff-47df-f6e7-10ccf4abd16c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed Documents:\n",
            "d1: ['herbivore', 'typically', 'plant', 'eater', 'meat', 'eater']\n",
            "d2: ['carnivore', 'typically', 'meat', 'eater', 'plant', 'eater']\n",
            "d3: ['deer', 'eat', 'grass', 'leaf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inverted_index = {}\n",
        "\n",
        "for doc_id, words in preprocessed_docs.items():\n",
        "    for word in words:\n",
        "        if word not in inverted_index:\n",
        "            inverted_index[word] = set()\n",
        "        inverted_index[word].add(doc_id)"
      ],
      "metadata": {
        "id": "nczve1J4DtHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word, doc_ids in inverted_index.items():\n",
        "    print(f\"{word}: {sorted(doc_ids)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luPE2vjWlwjq",
        "outputId": "5d066ff5-7b26-4009-a9a5-83a8667b6027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "herbivore: ['d1']\n",
            "typically: ['d1', 'd2']\n",
            "plant: ['d1', 'd2']\n",
            "eater: ['d1', 'd2']\n",
            "meat: ['d1', 'd2']\n",
            "carnivore: ['d2']\n",
            "deer: ['d3']\n",
            "eat: ['d3']\n",
            "grass: ['d3']\n",
            "leaf: ['d3']\n"
          ]
        }
      ]
    }
  ]
}